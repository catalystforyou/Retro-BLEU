{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "from queue import Queue\n",
    "from tqdm import tqdm\n",
    "from rdkit import Chem\n",
    "from collections import Counter\n",
    "from tqdm import trange, tqdm\n",
    "from BLEU_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_routes = pickle.load(open('data/all_routes.pickle', 'rb'))\n",
    "all_templates = json.load(open('../teamdrive/projects/n5routes/templates/all_routes_templates_1_0_0.json'))\n",
    "golden_dict = pickle.load(open('../teamdrive/projects/n5routes/templates/golden_dict.pickle', 'rb'))\n",
    "test_dict = json.load(open(f'data/test_routes_templates_1_0_0.json'))\n",
    "\n",
    "golden_routes = pickle.load(open('test_routes/routes_golden.pkl', 'rb'))\n",
    "retrostar_routes = json.load(open('test_routes/routes_retrostar.json'))['routes']\n",
    "retrostar_routes = [[rxn.split('>')[0] + '>>' + rxn.split('>')[-1] for rxn in route.split('|')] for route in retrostar_routes if isinstance(route, str)]\n",
    "retrostarplus_routes = json.load(open('test_routes/routes_retrostarplus.json'))['routes']\n",
    "retrostarplus_routes = [[rxn.split('>')[0] + '>>' + rxn.split('>')[-1] for rxn in route.split('|')] for route in retrostarplus_routes if isinstance(route, str)]\n",
    "egmcts_routes = json.load(open('test_routes/routes_egmcts.json'))['routes']\n",
    "egmcts_routes = [[rxn.split('>')[0] + '>>' + rxn.split('>')[-1] for rxn in route.split('|')] for route in egmcts_routes if isinstance(route, str)]\n",
    "retrograph_routes = json.load(open('test_routes/routes_retrograph.json'))\n",
    "golden_route_dict = build_route_dict(golden_routes)\n",
    "retrostar_route_dict = build_route_dict(retrostar_routes)\n",
    "retrostarplus_route_dict = build_route_dict(retrostarplus_routes)\n",
    "egmcts_route_dict = build_route_dict(egmcts_routes)\n",
    "retrograph_route_dict = build_route_dict(retrograph_routes)\n",
    "\n",
    "test_route_dicts = [golden_route_dict, retrostar_route_dict, retrostarplus_route_dict, egmcts_route_dict, retrograph_route_dict]\n",
    "targets = [routes[0].split('>>')[0] for routes in golden_routes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of n-gram rxns for n in [2, 3, 4, 5]: [818622, 342358, 141804, 56046]\n",
      "Number of n-gram templates for n in [2, 3, 4, 5]: [818622, 342358, 141804, 56046]\n",
      "Number of n-gram rxns for n in [2, 3, 4, 5]: [253758, 106978, 44796, 17836]\n",
      "Number of n-gram templates for n in [2, 3, 4, 5]: [112047, 69456, 31191, 12816]\n"
     ]
    }
   ],
   "source": [
    "all_ngram_rxns, all_ngram_templates, all_rxns = build_vocab(all_routes, all_templates)\n",
    "set_ngram_rxns = [set(ngram_rxns) for ngram_rxns in all_ngram_rxns]\n",
    "set_ngram_templates = [set(ngram_templates) for ngram_templates in all_ngram_templates]\n",
    "print('Number of n-gram rxns for n in [2, 3, 4, 5]:', [len(ngram_rxns) for ngram_rxns in all_ngram_rxns])\n",
    "print('Number of n-gram templates for n in [2, 3, 4, 5]:', [len(ngram_templates) for ngram_templates in all_ngram_templates])\n",
    "print('Number of n-gram rxns for n in [2, 3, 4, 5]:', [len(ngram_rxns) for ngram_rxns in set_ngram_rxns])\n",
    "print('Number of n-gram templates for n in [2, 3, 4, 5]:', [len(ngram_templates) for ngram_templates in set_ngram_templates])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vocab routes: 395121\n",
      "Number of test routes: 62326\n",
      "Number of n-gram rxns for n in [2, 3, 4, 5] in routes before 2013: [701854, 290944, 119587, 46628]\n",
      "Number of n-gram templates for n in [2, 3, 4, 5] in routes before 2013: [701854, 290944, 119587, 46628]\n",
      "Number of n-gram rxns for n in [2, 3, 4, 5] in routes before 2013: [227607, 95849, 39985, 15895]\n",
      "Number of n-gram templates for n in [2, 3, 4, 5] in routes before 2013: [102480, 62376, 27888, 11426]\n"
     ]
    }
   ],
   "source": [
    "vocab_routes = []\n",
    "test_routes = []\n",
    "for idx, route in enumerate(all_routes):\n",
    "    rxn_nodes = extract_rxns(route)\n",
    "    ID = rxn_nodes[0]['metadata']['ID'].split(';')[0][2:]\n",
    "    if ID[:4] in ['2014', '2015', '2016']:\n",
    "        test_routes.append(route)\n",
    "    else:\n",
    "        vocab_routes.append(route)\n",
    "print('Number of vocab routes:', len(vocab_routes))\n",
    "print('Number of test routes:', len(test_routes))\n",
    "all_ngram_rxns, all_ngram_templates, all_rxns = build_vocab(vocab_routes, all_templates)\n",
    "all_ngram_templates = [[tuple([all_templates[rxn] for rxn in curr_rxn_set]) for curr_rxn_set in n_gram_rxns] for n_gram_rxns in all_ngram_rxns]\n",
    "set_ngram_rxns = [set(ngram_rxns) for ngram_rxns in all_ngram_rxns]\n",
    "set_ngram_templates = [set(ngram_templates) for ngram_templates in all_ngram_templates]\n",
    "print('Number of n-gram rxns for n in [2, 3, 4, 5] in routes before 2013:', [len(ngram_rxns) for ngram_rxns in all_ngram_rxns])\n",
    "print('Number of n-gram templates for n in [2, 3, 4, 5] in routes before 2013:', [len(ngram_templates) for ngram_templates in all_ngram_templates])\n",
    "print('Number of n-gram rxns for n in [2, 3, 4, 5] in routes before 2013:', [len(ngram_rxns) for ngram_rxns in set_ngram_rxns])\n",
    "print('Number of n-gram templates for n in [2, 3, 4, 5] in routes before 2013:', [len(ngram_templates) for ngram_templates in set_ngram_templates])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n-gram rxn ratio for n in [2, 3, 4, 5] in routes after 2014: [0.6996204799240451, 0.7093509749685522, 0.7057417117264733, 0.7172911202697639]\n",
      "n-gram template ratio for n in [2, 3, 4, 5] in patents after 2014: [0.8236269022598164, 0.7340199872266381, 0.718275165219291, 0.7224085175471462]\n"
     ]
    }
   ],
   "source": [
    "bleu_ratio, bleu_template_ratio = evaluate_routes(test_routes, all_templates, set_ngram_templates, set_ngram_rxns)\n",
    "print(f'n-gram rxn ratio for n in [2, 3, 4, 5] in routes after 2014:', [np.mean(bleu_ratio[i]) for i in range(4)])\n",
    "print(f'n-gram template ratio for n in [2, 3, 4, 5] in patents after 2014:', [np.mean(bleu_template_ratio[i]) for i in range(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vocab routes: 367039\n",
      "Number of test routes: 90408\n",
      "Number of n-gram rxns for n in [2, 3, 4, 5]: [656777, 274853, 114104, 45076]\n",
      "Number of n-gram templates for n in [2, 3, 4, 5]: [656777, 274853, 114104, 45076]\n",
      "Number of n-gram rxns for n in [2, 3, 4, 5]: [233032, 98572, 41443, 16517]\n",
      "Number of n-gram templates for n in [2, 3, 4, 5]: [104128, 63992, 28780, 11856]\n"
     ]
    }
   ],
   "source": [
    "vocab_routes = []\n",
    "test_routes = []\n",
    "ID_random_dict = {}\n",
    "for idx, route in enumerate(all_routes):\n",
    "    rxn_nodes = extract_rxns(route)\n",
    "    ID = rxn_nodes[0]['metadata']['ID'].split(';')[0][2:]\n",
    "    if ID not in ID_random_dict:\n",
    "        ID_random_dict[ID] = np.random.random()\n",
    "    if ID_random_dict[ID] < 0.2:\n",
    "        test_routes.append(route)\n",
    "    else:\n",
    "        vocab_routes.append(route)\n",
    "print('Number of vocab routes:', len(vocab_routes))\n",
    "print('Number of test routes:', len(test_routes))\n",
    "all_ngram_rxns, all_ngram_templates, all_rxns = build_vocab(vocab_routes, all_templates)\n",
    "all_ngram_templates = [[tuple([all_templates[rxn] for rxn in curr_rxn_set]) for curr_rxn_set in n_gram_rxns] for n_gram_rxns in all_ngram_rxns]\n",
    "set_ngram_rxns = [set(ngram_rxns) for ngram_rxns in all_ngram_rxns]\n",
    "set_ngram_templates = [set(ngram_templates) for ngram_templates in all_ngram_templates]\n",
    "print('Number of n-gram rxns for n in [2, 3, 4, 5]:', [len(ngram_rxns) for ngram_rxns in all_ngram_rxns])\n",
    "print('Number of n-gram templates for n in [2, 3, 4, 5]:', [len(ngram_templates) for ngram_templates in all_ngram_templates])\n",
    "print('Number of n-gram rxns for n in [2, 3, 4, 5]:', [len(ngram_rxns) for ngram_rxns in set_ngram_rxns])\n",
    "print('Number of n-gram templates for n in [2, 3, 4, 5]:', [len(ngram_templates) for ngram_templates in set_ngram_templates])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n-gram rxn ratio for n in [2, 3, 4, 5] in routes after 2014: [0.8181359538697939, 0.8198119123038624, 0.8234518815352827, 0.8240287549709391]\n",
      "n-gram template ratio for n in [2, 3, 4, 5] in patents after 2014: [0.9022221887839422, 0.8463187975086193, 0.8341045227808737, 0.8332277236376349]\n"
     ]
    }
   ],
   "source": [
    "bleu_ratio, bleu_template_ratio = evaluate_routes(test_routes, all_templates, set_ngram_templates, set_ngram_rxns)\n",
    "print(f'n-gram rxn ratio for n in [2, 3, 4, 5] in routes after 2014:', [np.mean(bleu_ratio[i]) for i in range(4)])\n",
    "print(f'n-gram template ratio for n in [2, 3, 4, 5] in patents after 2014:', [np.mean(bleu_template_ratio[i]) for i in range(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vocab routes: 366171\n",
      "Number of test routes: 91276\n",
      "Number of n-gram rxns for n in [2, 3, 4, 5]: [655094, 273892, 113253, 44773]\n",
      "Number of n-gram templates for n in [2, 3, 4, 5]: [655094, 273892, 113253, 44773]\n",
      "Number of n-gram rxns for n in [2, 3, 4, 5] in routes before 2013: [233580, 98677, 41363, 16474]\n",
      "Number of n-gram templates for n in [2, 3, 4, 5] in routes before 2013: [105410, 64774, 29078, 11952]\n"
     ]
    }
   ],
   "source": [
    "vocab_routes = []\n",
    "test_routes = []\n",
    "ID_random_dict = {}\n",
    "for idx, route in enumerate(all_routes):\n",
    "    rxn_nodes = extract_rxns(route)\n",
    "    ID = rxn_nodes[0]['metadata']['ID'].split(';')[0][2:]\n",
    "    if np.random.random() < 0.2:\n",
    "        test_routes.append(route)\n",
    "    else:\n",
    "        vocab_routes.append(route)\n",
    "print('Number of vocab routes:', len(vocab_routes))\n",
    "print('Number of test routes:', len(test_routes))\n",
    "all_ngram_rxns, all_ngram_templates, all_rxns = build_vocab(vocab_routes, all_templates)\n",
    "all_ngram_templates = [[tuple([all_templates[rxn] for rxn in curr_rxn_set]) for curr_rxn_set in n_gram_rxns] for n_gram_rxns in all_ngram_rxns]\n",
    "set_ngram_rxns = [set(ngram_rxns) for ngram_rxns in all_ngram_rxns]\n",
    "set_ngram_templates = [set(ngram_templates) for ngram_templates in all_ngram_templates]\n",
    "print('Number of n-gram rxns for n in [2, 3, 4, 5]:', [len(ngram_rxns) for ngram_rxns in all_ngram_rxns])\n",
    "print('Number of n-gram templates for n in [2, 3, 4, 5]:', [len(ngram_templates) for ngram_templates in all_ngram_templates])\n",
    "print('Number of n-gram rxns for n in [2, 3, 4, 5] in routes before 2013:', [len(ngram_rxns) for ngram_rxns in set_ngram_rxns])\n",
    "print('Number of n-gram templates for n in [2, 3, 4, 5] in routes before 2013:', [len(ngram_templates) for ngram_templates in set_ngram_templates])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n-gram rxn ratio for n in [2, 3, 4, 5] in routes after 2014: [0.8313650309730879, 0.8326491591154864, 0.8309504138575592, 0.8329959407175628]\n",
      "n-gram template ratio for n in [2, 3, 4, 5] in patents after 2014: [0.9420270617154245, 0.9046105911258613, 0.8973180101444519, 0.8948607088240061]\n"
     ]
    }
   ],
   "source": [
    "bleu_ratio, bleu_template_ratio = evaluate_routes(test_routes, all_templates, set_ngram_templates, set_ngram_rxns)\n",
    "print(f'n-gram rxn ratio for n in [2, 3, 4, 5] in routes after 2014:', [np.mean(bleu_ratio[i]) for i in range(4)])\n",
    "print(f'n-gram template ratio for n in [2, 3, 4, 5] in patents after 2014:', [np.mean(bleu_template_ratio[i]) for i in range(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.789545018329992"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([len(extract_rxns(route)) for route in all_routes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ngram_rxns, all_ngram_templates, all_rxns = build_vocab(all_routes, all_templates)\n",
    "set_ngram_rxns = [set(ngram_rxns) for ngram_rxns in all_ngram_rxns]\n",
    "set_ngram_templates = [set(ngram_templates) for ngram_templates in all_ngram_templates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n-gram rxn ratio for n in [2, 3, 4, 5]: [0.0, 0.0, 0.0, 0.0]\n",
      "n-gram template ratio for n in [2, 3, 4, 5]: [0.24456292245765926, 0.13057631967515687, 0.09487612612612613, 0.06789617486338799]\n"
     ]
    }
   ],
   "source": [
    "golden_routes = pickle.load(open('test_routes/routes_golden.pkl', 'rb'))\n",
    "bleu_ratio, bleu_template_ratio = evaluate_routes(golden_routes, test_dict, set_ngram_templates, set_ngram_rxns)\n",
    "print(f'n-gram rxn ratio for n in [2, 3, 4, 5]:', [np.mean(bleu_ratio[i]) for i in range(4)])\n",
    "print(f'n-gram template ratio for n in [2, 3, 4, 5]:', [np.mean(bleu_template_ratio[i]) for i in range(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n-gram rxn ratio for n in [2, 3, 4, 5]: [0.0, 0.0, 0.0, 0.0]\n",
      "n-gram template ratio for n in [2, 3, 4, 5]: [0.20682935751117565, 0.07747942696572833, 0.05364823348694316, 0.0405040504050405]\n"
     ]
    }
   ],
   "source": [
    "retro_routes = json.load(open('test_routes/routes_retrostar.json'))['routes']\n",
    "retro_routes = [[rxn.split('>')[0] + '>>' + rxn.split('>')[-1] for rxn in route.split('|')] for route in retro_routes if isinstance(route, str)]\n",
    "bleu_ratio, bleu_template_ratio = evaluate_routes(retro_routes, test_dict, set_ngram_templates, set_ngram_rxns)\n",
    "print(f'n-gram rxn ratio for n in [2, 3, 4, 5]:', [np.mean(bleu_ratio[i]) for i in range(4)])\n",
    "print(f'n-gram template ratio for n in [2, 3, 4, 5]:', [np.mean(bleu_template_ratio[i]) for i in range(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n-gram rxn ratio for n in [2, 3, 4, 5]: [0.0, 0.0, 0.0, 0.0]\n",
      "n-gram template ratio for n in [2, 3, 4, 5]: [0.20545199336182943, 0.08639840748274483, 0.06358447488584475, 0.041666666666666664]\n"
     ]
    }
   ],
   "source": [
    "retro_routes = json.load(open('test_routes/routes_retrostarplus.json'))['routes']\n",
    "retro_routes = [[rxn.split('>')[0] + '>>' + rxn.split('>')[-1] for rxn in route.split('|')] for route in retro_routes if isinstance(route, str)]\n",
    "bleu_ratio, bleu_template_ratio = evaluate_routes(retro_routes, test_dict, set_ngram_templates, set_ngram_rxns)\n",
    "print(f'n-gram rxn ratio for n in [2, 3, 4, 5]:', [np.mean(bleu_ratio[i]) for i in range(4)])\n",
    "print(f'n-gram template ratio for n in [2, 3, 4, 5]:', [np.mean(bleu_template_ratio[i]) for i in range(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n-gram rxn ratio for n in [2, 3, 4, 5]: [0.0, 0.0, 0.0, 0.0]\n",
      "n-gram template ratio for n in [2, 3, 4, 5]: [0.09017300246808442, 0.03085858585858586, 0.009667024704618688, 0.0]\n"
     ]
    }
   ],
   "source": [
    "retro_routes = json.load(open('test_routes/routes_egmcts.json'))['routes']\n",
    "retro_routes = [[rxn.split('>')[0] + '>>' + rxn.split('>')[-1] for rxn in route.split('|')] for route in retro_routes if isinstance(route, str)]\n",
    "bleu_ratio, bleu_template_ratio = evaluate_routes(retro_routes, test_dict, set_ngram_templates, set_ngram_rxns)\n",
    "print(f'n-gram rxn ratio for n in [2, 3, 4, 5]:', [np.mean(bleu_ratio[i]) for i in range(4)])\n",
    "print(f'n-gram template ratio for n in [2, 3, 4, 5]:', [np.mean(bleu_template_ratio[i]) for i in range(4)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n-gram rxn ratio for n in [2, 3, 4, 5]: [0.0, 0.0, 0.0, 0.0]\n",
      "n-gram template ratio for n in [2, 3, 4, 5]: [0.12513487394439776, 0.034314807999018516, 0.011267605633802818, 0.0022727272727272726]\n"
     ]
    }
   ],
   "source": [
    "retro_routes = json.load(open('test_routes/routes_retrograph.json'))\n",
    "bleu_ratio, bleu_template_ratio = evaluate_routes(retro_routes, test_dict, set_ngram_templates, set_ngram_rxns)\n",
    "print(f'n-gram rxn ratio for n in [2, 3, 4, 5]:', [np.mean(bleu_ratio[i]) for i in range(4)])\n",
    "print(f'n-gram template ratio for n in [2, 3, 4, 5]:', [np.mean(bleu_template_ratio[i]) for i in range(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [[] for _ in range(len(test_route_dicts))]\n",
    "for target in targets:\n",
    "    curr_routes = [test_route_dict[target] for test_route_dict in test_route_dicts if target in test_route_dict]\n",
    "    candidate_bleu = retrostar_route_bleu(curr_routes, neg_bigram, pos_bigram, test_dict)\n",
    "    for idx, test_route_dict in enumerate(test_route_dicts):\n",
    "        if target in test_route_dict:\n",
    "            scores[idx].append(candidate_bleu.pop(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-2.09863789762503,\n",
       " -2.1139270864471302,\n",
       " -2.057105227851097,\n",
       " -2.0163386368882064,\n",
       " -2.010137764992542]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.mean(score) for score in scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aizynth-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
